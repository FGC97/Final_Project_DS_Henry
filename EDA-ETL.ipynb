{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOOGLE MAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carpeta \"metadata-sitios\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo variables con el path de cada archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"metadata-sitios/1.json\"\n",
    "path2= \"metadata-sitios/2.json\"\n",
    "path3 = \"metadata-sitios/3.json\"\n",
    "path4= \"metadata-sitios/4.json\"\n",
    "path5 = \"metadata-sitios/5.json\"\n",
    "path6= \"metadata-sitios/6.json\"\n",
    "path7 = \"metadata-sitios/7.json\"\n",
    "path8= \"metadata-sitios/8.json\"\n",
    "path9 = \"metadata-sitios/9.json\"\n",
    "path10= \"metadata-sitios/10.json\"\n",
    "path11 = \"metadata-sitios/11.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de rutas de archivos JSON\n",
    "paths = [ path1,path2,path3,\n",
    "          path4,path5,path6,\n",
    "          path7,path8,path9,\n",
    "          path10,path11 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_gm_metadata_files(paths):\n",
    "    result_dataframes = []\n",
    "# EXTRACCIÓN\n",
    "    for path in paths:\n",
    "        # Leer el archivo JSON y convertirlo en DataFrame\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        \n",
    "# TRANSFORMACIÓN\n",
    "        # Reemplaza la columna \"state\" y normalizar por el ISO del estado\n",
    "        df['state'] = df['address'].str.upper()\n",
    "        df['state'] = df['state'].str.replace('FLORIDA', 'FL')\n",
    "        df['state'] = df['state'].str.replace('CALIFORNIA', 'CA')\n",
    "        df['state'] = df['state'].str.replace('TEXAS', 'TX')\n",
    "\n",
    "        # Revisar los registros que contienen el ISO o el nombre de los estados y reemplazar por el ISO correspondiente\n",
    "        df['state'] = df.apply(lambda row: 'FL' if row['state'] is not None and ('FL' in row['state'] or 'FLORIDA' in row['state']) else row['state'], axis=1)\n",
    "        df['state'] = df.apply(lambda row: 'CA' if row['state'] is not None and ('CA' in row['state'] or 'CALIFORNIA' in row['state']) else row['state'], axis=1)\n",
    "        df['state'] = df.apply(lambda row: 'TX' if row['state'] is not None and ('TX' in row['state'] or 'TEXAS' in row['state']) else row['state'], axis=1)\n",
    "        \n",
    "        #Filtrar por los estados determinados\n",
    "        df = df[df['state'].isin(['CA', 'FL', 'TX'])]\n",
    "        \n",
    "        # Lista de palabras clave a buscar\n",
    "        palabras_clave = ['restaurant', 'cafe', 'cafeteria', 'food', 'fast food', 'fastfood', 'mexican food', 'hamburger']\n",
    "\n",
    "        # Función para buscar coincidencias de palabras clave en la lista de strings\n",
    "        def buscar_coincidencias(lista):\n",
    "            if lista is None:\n",
    "                return False\n",
    "            else:\n",
    "                texto = ' '.join(lista).lower()\n",
    "                for palabra in palabras_clave:\n",
    "                    if re.search(r'\\b' + re.escape(palabra.lower()) + r'\\b', texto):\n",
    "                        return True\n",
    "                return False\n",
    "\n",
    "        # Verificar si alguna palabra clave está presente en las listas de strings de la columna 'category'\n",
    "        df['contains_keyword'] = df['category'].apply(buscar_coincidencias)      \n",
    "        # Crear columna y verificar si alguna palabra clave está presente en las listas de strings de la columna 'category'\n",
    "        #df['contains_keyword'] = df['category'].apply(buscar_coincidencias_rubro_restaurantes)\n",
    "        \n",
    "        # Filtrar el DataFrame para obtener solo las filas que contienen palabras clave (los que sean TRUE)\n",
    "        df = df[df['contains_keyword']]\n",
    "\n",
    "        # Eliminar la columna 'contains_keyword' si ya no es necesaria\n",
    "        df.drop('contains_keyword', axis=1, inplace=True)\n",
    "\n",
    "        # Borrar duplicados de gmap_id:\n",
    "        df.drop_duplicates(subset=\"gmap_id\", inplace=True)\n",
    "        \n",
    "        # Eliminar columnas innecesarias:\n",
    "        columns = [\"description\", \"hours\", \"price\", \"url\", \"relative_results\"]\n",
    "        df.drop(columns, axis=1, inplace=True)\n",
    "        \n",
    "        # Agregar el DataFrame final a la lista de resultados\n",
    "        result_dataframes.append(df)\n",
    "        \n",
    "   \n",
    "        \n",
    "    # Une los DataFrames verticalmente\n",
    "    merged_dataframe = pd.concat(result_dataframes, axis=0)\n",
    "\n",
    "    # Reiniciar los índices \n",
    "    merged_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# CARGA    \n",
    "    merged_dataframe.to_csv('POST_ETL_DATASETS/gm_metadata.csv', index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    return merged_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_metadata= process_gm_metadata_files(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104968 entries, 0 to 104967\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   name            104968 non-null  object \n",
      " 1   address         104968 non-null  object \n",
      " 2   gmap_id         104968 non-null  object \n",
      " 3   latitude        104968 non-null  float64\n",
      " 4   longitude       104968 non-null  float64\n",
      " 5   category        104968 non-null  object \n",
      " 6   avg_rating      104968 non-null  float64\n",
      " 7   num_of_reviews  104968 non-null  int64  \n",
      " 8   MISC            103604 non-null  object \n",
      " 9   state           104968 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "gm_metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Service options': ['Takeout', 'Dine-in', 'Delivery'],\n",
       " 'Accessibility': ['Wheelchair accessible entrance'],\n",
       " 'Offerings': ['Comfort food'],\n",
       " 'Amenities': ['Good for kids'],\n",
       " 'Atmosphere': ['Casual']}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_metadata.MISC[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporto el dataframe ya limpio a un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_metadata.to_csv('POST_ETL_DATASETS/gm_metadata.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carpeta \"reviews-estados\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que nuestro objetivo general se centra en los estado con mayor pobalción de latinos, el alcance será solo en los estados California , Florida y Texas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### California\n",
    "\n",
    "* Creo variables con el paths de cada archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal1 = \"reviews-estados/review-California/1.json\"\n",
    "cal2 = \"reviews-estados/review-California/2.json\"\n",
    "cal3 = \"reviews-estados/review-California/3.json\"\n",
    "cal4 = \"reviews-estados/review-California/4.json\"\n",
    "cal5 = \"reviews-estados/review-California/5.json\"\n",
    "cal6 = \"reviews-estados/review-California/6.json\"\n",
    "cal7 = \"reviews-estados/review-California/7.json\"\n",
    "cal8 = \"reviews-estados/review-California/8.json\"\n",
    "cal9 = \"reviews-estados/review-California/9.json\"\n",
    "cal10 = \"reviews-estados/review-California/10.json\"\n",
    "cal11 = \"reviews-estados/review-California/11.json\"\n",
    "cal12 = \"reviews-estados/review-California/12.json\"\n",
    "cal13 = \"reviews-estados/review-California/13.json\"\n",
    "cal14 = \"reviews-estados/review-California/14.json\"\n",
    "cal15 =\"reviews-estados/review-California/15.json\"\n",
    "cal16 = \"reviews-estados/review-California/16.json\"\n",
    "cal17 = \"reviews-estados/review-California/17.json\"\n",
    "cal18 = \"reviews-estados/review-California/18.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtengo el primer dataset en un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\HENRY\\CARRERA DATA SCIENCE\\Proyecto Grupal\\functions.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/HENRY/CARRERA%20DATA%20SCIENCE/Proyecto%20Grupal/functions.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cal_1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(cal1, lines\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/HENRY/CARRERA%20DATA%20SCIENCE/Proyecto%20Grupal/functions.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cal_1_copy \u001b[39m=\u001b[39m cal_1\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/HENRY/CARRERA%20DATA%20SCIENCE/Proyecto%20Grupal/functions.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cal_1_copy\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[0;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 784\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:973\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    971\u001b[0m         data \u001b[39m=\u001b[39m ensure_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m    972\u001b[0m         data_lines \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 973\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_combine_lines(data_lines))\n\u001b[0;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    999\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1001\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[0;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 1134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n\u001b[0;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\json\\_json.py:1319\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1316\u001b[0m orient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\n\u001b[0;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[0;32m   1320\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1323\u001b[0m     decoded \u001b[39m=\u001b[39m {\n\u001b[0;32m   1324\u001b[0m         \u001b[39mstr\u001b[39m(k): v\n\u001b[0;32m   1325\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m loads(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1326\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:781\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    780\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 781\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    782\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    783\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m         data,\n\u001b[0;32m    785\u001b[0m         columns,\n\u001b[0;32m    786\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    787\u001b[0m         dtype,\n\u001b[0;32m    788\u001b[0m     )\n\u001b[0;32m    789\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    790\u001b[0m         arrays,\n\u001b[0;32m    791\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    795\u001b[0m     )\n\u001b[0;32m    796\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    499\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    501\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:832\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    830\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m    831\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], abc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m--> 832\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n\u001b[0;32m    833\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m    834\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_series_to_arrays(data, columns)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:912\u001b[0m, in \u001b[0;36m_list_of_dict_to_arrays\u001b[1;34m(data, columns)\u001b[0m\n\u001b[0;32m    910\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    911\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[1;32m--> 912\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39;49msort)\n\u001b[0;32m    913\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(pre_cols)\n\u001b[0;32m    915\u001b[0m \u001b[39m# assure that they are of the base dict class and not of derived\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[39m# classes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:374\u001b[0m, in \u001b[0;36mpandas._libs.lib.fast_unique_multiple_list_gen\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:910\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[39mConvert list of dicts to numpy arrays\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[39mcolumns : Index\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 910\u001b[0m     gen \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39;49mkeys()) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    911\u001b[0m     sort \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data)\n\u001b[0;32m    912\u001b[0m     pre_cols \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_unique_multiple_list_gen(gen, sort\u001b[39m=\u001b[39msort)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cal_1 = pd.read_json(cal1, lines= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Genero una copia del df para poder explorarlo sin modificar nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.089912e+20</td>\n",
       "      <td>Song Ro</td>\n",
       "      <td>1609909927056</td>\n",
       "      <td>5</td>\n",
       "      <td>Love there korean rice cake.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.112903e+20</td>\n",
       "      <td>Rafa Robles</td>\n",
       "      <td>1612849648663</td>\n",
       "      <td>5</td>\n",
       "      <td>Good very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126404e+20</td>\n",
       "      <td>David Han</td>\n",
       "      <td>1583643882296</td>\n",
       "      <td>4</td>\n",
       "      <td>They make Korean traditional food very properly.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.174403e+20</td>\n",
       "      <td>Anthony Kim</td>\n",
       "      <td>1551938216355</td>\n",
       "      <td>5</td>\n",
       "      <td>Short ribs are very delicious.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.005808e+20</td>\n",
       "      <td>Mario Marzouk</td>\n",
       "      <td>1494910901933</td>\n",
       "      <td>5</td>\n",
       "      <td>Great food and prices the portions are large</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id           name           time  rating   \n",
       "0  1.089912e+20        Song Ro  1609909927056       5  \\\n",
       "1  1.112903e+20    Rafa Robles  1612849648663       5   \n",
       "2  1.126404e+20      David Han  1583643882296       4   \n",
       "3  1.174403e+20    Anthony Kim  1551938216355       5   \n",
       "4  1.005808e+20  Mario Marzouk  1494910901933       5   \n",
       "\n",
       "                                               text  pics  resp   \n",
       "0                      Love there korean rice cake.  None  None  \\\n",
       "1                                    Good very good  None  None   \n",
       "2  They make Korean traditional food very properly.  None  None   \n",
       "3                    Short ribs are very delicious.  None  None   \n",
       "4      Great food and prices the portions are large  None  None   \n",
       "\n",
       "                                 gmap_id  \n",
       "0  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "1  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "2  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "3  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "4  0x80c2c778e3b73d33:0xbdc58662a4a97d49  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_1_copy = cal_1.copy()\n",
    "cal_1_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reviso su información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   user_id  150000 non-null  float64\n",
      " 1   name     150000 non-null  object \n",
      " 2   time     150000 non-null  int64  \n",
      " 3   rating   150000 non-null  int64  \n",
      " 4   text     89135 non-null   object \n",
      " 5   pics     5632 non-null    object \n",
      " 6   resp     16935 non-null   object \n",
      " 7   gmap_id  150000 non-null  object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "cal_1_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior:\n",
    "\n",
    "* Hay muchos nulos en la columna *text* y *resp*; esto conviene reviarlo nuevamente después de unir los datasets de reviews  pertenecientes a cada estado para confirmar si representará un problema.\n",
    "* La columna *time* debe ser pasada a fecha.\n",
    "* Filtrar a partir del año 2018 ya que nos interesan los datos más actuales.\n",
    "* Filtrar solo por restaurantes.\n",
    "* Columnas innecesarias: *pics* y *name*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el tipo de dato de la columna *time* a date_time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2021-01-06\n",
       "1    2021-02-09\n",
       "2    2020-03-08\n",
       "3    2019-03-07\n",
       "4    2017-05-16\n",
       "Name: time, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Especifico la unidad de tiempo en la están los registros (ms) y lo convierto a fecha:\n",
    "cal_1_copy['time'] = pd.to_datetime(cal_1_copy['time'], unit='ms').dt.date\n",
    "\n",
    "# Reviso el cambio:\n",
    "cal_1_copy['time'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifico el tipo de dato:\n",
    "type(cal_1_copy.time[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviso la fecha más antigua y más reciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-04-07\n",
      "2021-09-09\n"
     ]
    }
   ],
   "source": [
    "print(cal_1_copy['time'].min())\n",
    "print(cal_1_copy['time'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviso cúantos registros hay a partir del año 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118152, 8)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_1_copy[cal_1_copy['time'].apply(lambda x: x.year)>=2018].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro a partir del año 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_1_copy=cal_1_copy[cal_1_copy['time'].apply(lambda x: x.year)>=2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro solo los restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero una lista de los gmap_id de los restaurantes del df gmap_metadata:\n",
    "lista_id_rest= list(gm_metadata['gmap_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>pics</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.089912e+20</td>\n",
       "      <td>Song Ro</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>5</td>\n",
       "      <td>Love there korean rice cake.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.112903e+20</td>\n",
       "      <td>Rafa Robles</td>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>5</td>\n",
       "      <td>Good very good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126404e+20</td>\n",
       "      <td>David Han</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>4</td>\n",
       "      <td>They make Korean traditional food very properly.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.174403e+20</td>\n",
       "      <td>Anthony Kim</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>5</td>\n",
       "      <td>Short ribs are very delicious.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.001857e+20</td>\n",
       "      <td>Ana Salazar</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>5</td>\n",
       "      <td>This food is delicious 😁</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         name        time  rating   \n",
       "0  1.089912e+20      Song Ro  2021-01-06       5  \\\n",
       "1  1.112903e+20  Rafa Robles  2021-02-09       5   \n",
       "2  1.126404e+20    David Han  2020-03-08       4   \n",
       "3  1.174403e+20  Anthony Kim  2019-03-07       5   \n",
       "5  1.001857e+20  Ana Salazar  2019-01-18       5   \n",
       "\n",
       "                                               text  pics  resp   \n",
       "0                      Love there korean rice cake.  None  None  \\\n",
       "1                                    Good very good  None  None   \n",
       "2  They make Korean traditional food very properly.  None  None   \n",
       "3                    Short ribs are very delicious.  None  None   \n",
       "5                          This food is delicious 😁  None  None   \n",
       "\n",
       "                                 gmap_id  \n",
       "0  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "1  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "2  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "3  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "5  0x80c2c778e3b73d33:0xbdc58662a4a97d49  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtro los establecimientos de California a partir de la lista anterior:\n",
    "cal_1_restaurantes = cal_1_copy[cal_1_copy['gmap_id'].isin(lista_id_rest)]\n",
    "\n",
    "\n",
    "\n",
    "# Reviso el dataframe:\n",
    "cal_1_restaurantes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, elimino las columnas innecesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_1_restaurantes = cal_1_restaurantes.drop(['name','pics'], axis=1)\n",
    "\n",
    "# Reviso el dataframe:\n",
    "cal_1_restaurantes.head()\n",
    "print(cal_1_restaurantes.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10840 entries, 0 to 149999\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   user_id  10840 non-null  float64\n",
      " 1   time     10840 non-null  object \n",
      " 2   rating   10840 non-null  int64  \n",
      " 3   text     6415 non-null   object \n",
      " 4   resp     932 non-null    object \n",
      " 5   gmap_id  10840 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 592.8+ KB\n"
     ]
    }
   ],
   "source": [
    "cal_1_restaurantes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las transformaciones necesarias ya están realizadas. A partir de estas creo una función que permita automatizar el ETL de los reviews de cada estado (California, Florida y Texas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gm_reviews_files(paths, state, df_metadata):\n",
    "    result_dataframes = []\n",
    "# EXTRACCIÓN\n",
    "    for path in paths:\n",
    "        # Leer el archivo JSON y convertirlo en DataFrame\n",
    "        df = pd.read_json(path, lines=True)\n",
    "        \n",
    "# TRANSFORMACIÓN        \n",
    "        # Especifico la unidad de tiempo en la están los registros (ms) y lo convierto a fecha:\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms').dt.date\n",
    "\n",
    "        # Filtro a partir del año 2018:\n",
    "        df=df[df['time'].apply(lambda x: x.year)>=2018]\n",
    "        \n",
    "        # Genero una lista de los gmap_id de los restaurantes del df gmap_metadata:\n",
    "        lista_id_restaurantes= list(df_metadata['gmap_id'])\n",
    "        \n",
    "        # Filtro los establecimientos de California a partir de la lista anterior:\n",
    "        df = df[df['gmap_id'].isin(lista_id_rest)]\n",
    "        \n",
    "        # Eliminar columnas innecesarias:\n",
    "        df = df.drop(['name','pics'], axis=1)\n",
    "\n",
    "        # Agregar columna con estado para poder filtrar por ese campo posteriormente:\n",
    "        df['state']= state\n",
    "        \n",
    "        # Agregar el DataFrame final a la lista de resultados\n",
    "        result_dataframes.append(df)\n",
    "       \n",
    "       \n",
    "    # Une los DataFrames verticalmente\n",
    "    merged_dataframe = pd.concat(result_dataframes, axis=0)\n",
    "\n",
    "    # Reiniciar los índices \n",
    "    merged_dataframe.reset_index(drop=True, inplace=True)\n",
    "#CARGA\n",
    "    merged_dataframe.to_csv(f'POST_ETL_DATASETS/gm_reviews_{state}.csv', index=False, encoding=\"utf-8\")\n",
    "    \n",
    "    return merged_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una lista con los paths de cada json correspondiente a los reviews de California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[cal1, cal2 , cal3, cal4, cal5, cal6, cal7, cal8, cal9,\n",
    "       cal10, cal11 , cal12, cal13, cal14, cal15, cal16, cal17, cal18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico la función para extraer, transformar y carga los datasets de California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_CA= process_gm_reviews_files(paths, \"CA\", gm_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651888 entries, 0 to 651887\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   user_id  651888 non-null  float64\n",
      " 1   time     651888 non-null  object \n",
      " 2   rating   651888 non-null  int64  \n",
      " 3   text     364047 non-null  object \n",
      " 4   resp     50941 non-null   object \n",
      " 5   gmap_id  651888 non-null  object \n",
      " 6   state    651888 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 34.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651883</th>\n",
       "      <td>1.129951e+20</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2956b34fc26c1:0x2f3b0897def449d6</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651884</th>\n",
       "      <td>1.023084e+20</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2956b34fc26c1:0x2f3b0897def449d6</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651885</th>\n",
       "      <td>1.125047e+20</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2956b34fc26c1:0x2f3b0897def449d6</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651886</th>\n",
       "      <td>1.021824e+20</td>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2956b34fc26c1:0x2f3b0897def449d6</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651887</th>\n",
       "      <td>1.155405e+20</td>\n",
       "      <td>2021-01-16</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x80c2956b34fc26c1:0x2f3b0897def449d6</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        time  rating  text  resp   \n",
       "651883  1.129951e+20  2019-07-07       5  None  None  \\\n",
       "651884  1.023084e+20  2020-01-15       4  None  None   \n",
       "651885  1.125047e+20  2018-10-10       4  None  None   \n",
       "651886  1.021824e+20  2018-08-28       5  None  None   \n",
       "651887  1.155405e+20  2021-01-16       5  None  None   \n",
       "\n",
       "                                      gmap_id state  \n",
       "651883  0x80c2956b34fc26c1:0x2f3b0897def449d6    CA  \n",
       "651884  0x80c2956b34fc26c1:0x2f3b0897def449d6    CA  \n",
       "651885  0x80c2956b34fc26c1:0x2f3b0897def449d6    CA  \n",
       "651886  0x80c2956b34fc26c1:0x2f3b0897def449d6    CA  \n",
       "651887  0x80c2956b34fc26c1:0x2f3b0897def449d6    CA  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso: \n",
    "print(reviews_CA.info())\n",
    "reviews_CA.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Florida\n",
    "\n",
    "* Creo variables con el path de cada archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida1 =\"reviews-estados/review-Florida/1.json\"\n",
    "florida2 =\"reviews-estados/review-Florida/2.json\"\n",
    "florida3 =\"reviews-estados/review-Florida/3.json\"\n",
    "florida4 =\"reviews-estados/review-Florida/4.json\"\n",
    "florida5 =\"reviews-estados/review-Florida/5.json\"\n",
    "florida6 =\"reviews-estados/review-Florida/6.json\"\n",
    "florida7 =\"reviews-estados/review-Florida/7.json\"\n",
    "florida8 =\"reviews-estados/review-Florida/8.json\"\n",
    "florida9 =\"reviews-estados/review-Florida/9.json\"\n",
    "florida10 =\"reviews-estados/review-Florida/10.json\"\n",
    "florida11 =\"reviews-estados/review-Florida/11.json\"\n",
    "florida12 =\"reviews-estados/review-Florida/12.json\"\n",
    "florida13 =\"reviews-estados/review-Florida/13.json\"\n",
    "florida14 =\"reviews-estados/review-Florida/14.json\"\n",
    "florida15 =\"reviews-estados/review-Florida/15.json\"\n",
    "florida16 =\"reviews-estados/review-Florida/16.json\"\n",
    "florida17 =\"reviews-estados/review-Florida/17.json\"\n",
    "florida18 =\"reviews-estados/review-Florida/18.json\"\n",
    "florida19 =\"reviews-estados/review-Florida/19.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una lista con los paths de los reviews de Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths= [florida1, florida2, florida3, florida4, florida5, florida6, florida7, florida8,florida9, florida10,\n",
    "        florida11, florida12, florida13, florida14, florida15, florida16, florida17, florida18, florida19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLamo a la función para extraer, limpiar y cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_FL= process_gm_reviews_files(paths, \"FL\", gm_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el archivo\n",
    "reviews_FL.to_csv(f'POST_ETL_DATASETS/gm_reviews_FL.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889304 entries, 0 to 889303\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   user_id  889304 non-null  float64\n",
      " 1   time     889304 non-null  object \n",
      " 2   rating   889304 non-null  int64  \n",
      " 3   text     537991 non-null  object \n",
      " 4   resp     127797 non-null  object \n",
      " 5   gmap_id  889304 non-null  object \n",
      " 6   state    889304 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 47.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>resp</th>\n",
       "      <th>gmap_id</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889299</th>\n",
       "      <td>1.055903e+20</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0x88e77b72f6649745:0x79b4f1ce48d76510</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889300</th>\n",
       "      <td>1.005875e+20</td>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'time': 1558395889016, 'text': 'Thank you, we...</td>\n",
       "      <td>0x88e77b72f6649745:0x79b4f1ce48d76510</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889301</th>\n",
       "      <td>1.102315e+20</td>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>{'time': 1566865864044, 'text': 'We will striv...</td>\n",
       "      <td>0x88e77b72f6649745:0x79b4f1ce48d76510</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889302</th>\n",
       "      <td>1.056372e+20</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>{'time': 1575306132300, 'text': 'We will striv...</td>\n",
       "      <td>0x88e77b72f6649745:0x79b4f1ce48d76510</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889303</th>\n",
       "      <td>1.137923e+20</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>{'time': 1554383797677, 'text': 'Thank you for...</td>\n",
       "      <td>0x88e77b72f6649745:0x79b4f1ce48d76510</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        time  rating  text   \n",
       "889299  1.055903e+20  2018-11-13       5  None  \\\n",
       "889300  1.005875e+20  2019-05-19       4  None   \n",
       "889301  1.102315e+20  2019-08-25       3  None   \n",
       "889302  1.056372e+20  2019-12-02       3  None   \n",
       "889303  1.137923e+20  2019-04-02       4  None   \n",
       "\n",
       "                                                     resp   \n",
       "889299                                               None  \\\n",
       "889300  {'time': 1558395889016, 'text': 'Thank you, we...   \n",
       "889301  {'time': 1566865864044, 'text': 'We will striv...   \n",
       "889302  {'time': 1575306132300, 'text': 'We will striv...   \n",
       "889303  {'time': 1554383797677, 'text': 'Thank you for...   \n",
       "\n",
       "                                      gmap_id state  \n",
       "889299  0x88e77b72f6649745:0x79b4f1ce48d76510    FL  \n",
       "889300  0x88e77b72f6649745:0x79b4f1ce48d76510    FL  \n",
       "889301  0x88e77b72f6649745:0x79b4f1ce48d76510    FL  \n",
       "889302  0x88e77b72f6649745:0x79b4f1ce48d76510    FL  \n",
       "889303  0x88e77b72f6649745:0x79b4f1ce48d76510    FL  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso: \n",
    "print(reviews_FL.info())\n",
    "reviews_FL.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FALTA\n",
    "* Eda de la primera función\n",
    "* Añadir a la función el desanidado\n",
    "* (tener en cuenta que el promedio de rating de metadata considera todos los años. (sacar nueva columna?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
